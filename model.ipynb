{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "756a3d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "043cdf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_subset(folder_path, sample_size=1000):\n",
    "    dfs = []\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith(\".parquet\"):\n",
    "            df = pd.read_parquet(os.path.join(folder_path, file))\n",
    "            dfs.append(df)\n",
    "    df_all = pd.concat(dfs, ignore_index=True)\n",
    "    #df_all = df_all.sample(n=sample_size, random_state=42)  # subset\n",
    "    return df_all\n",
    "\n",
    "def train_model_and_save(file):\n",
    "    train_df = pd.read_parquet(os.path.join(\"emisoras_parquet\", file))\n",
    "\n",
    "    train_df['fechaEnvioCobro'] = pd.to_datetime(train_df['fechaEnvioCobro'], errors='coerce')\n",
    "    train_df['target_success'] = train_df['fechaEnvioCobro'].notna().astype(int)\n",
    "\n",
    "    features = ['montoCobrar', 'transCount', 'IdBanco_Credito',\n",
    "                'pagoAnterior', 'ratioAnterior', 'residualAnterior', 'idEmisora']\n",
    "\n",
    "    train_df = train_df.dropna(subset=features)\n",
    "\n",
    "    X_train = train_df[features].copy()\n",
    "    y_train = train_df['target_success']\n",
    "\n",
    "    X_train = pd.get_dummies(X_train, columns=['IdBanco_Credito', 'idEmisora'], drop_first=True)\n",
    "    X_train['montoCobrar'] = np.log1p(X_train['montoCobrar'])\n",
    "\n",
    "    numeric_cols = ['montoCobrar', 'transCount', 'pagoAnterior', 'ratioAnterior', 'residualAnterior']\n",
    "    scaler = StandardScaler()\n",
    "    X_train[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
    "\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Save model and scaler\n",
    "    joblib.dump(model, os.path.join(\"modelOut\", file))\n",
    "\n",
    "    print(f\"✅ Modelo guardado en: {file}\")\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7ac709a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = pd.DataFrame({\"files\":os.listdir(\"D:\\Datathon 2025\\emisoras_parquet\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "60cf525c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Modelo guardado en: emisora_1.parquet\n",
      "✅ Modelo guardado en: emisora_10.parquet\n",
      "✅ Modelo guardado en: emisora_11.parquet\n",
      "✅ Modelo guardado en: emisora_12.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmanu\\AppData\\Local\\Temp\\ipykernel_3648\\3717017581.py:14: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  train_df['fechaEnvioCobro'] = pd.to_datetime(train_df['fechaEnvioCobro'], errors='coerce')\n",
      "C:\\Users\\jmanu\\AppData\\Local\\Temp\\ipykernel_3648\\3717017581.py:14: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  train_df['fechaEnvioCobro'] = pd.to_datetime(train_df['fechaEnvioCobro'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Modelo guardado en: emisora_13.parquet\n",
      "✅ Modelo guardado en: emisora_14.parquet\n",
      "✅ Modelo guardado en: emisora_15.parquet\n",
      "✅ Modelo guardado en: emisora_16.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmanu\\AppData\\Local\\Temp\\ipykernel_3648\\3717017581.py:14: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  train_df['fechaEnvioCobro'] = pd.to_datetime(train_df['fechaEnvioCobro'], errors='coerce')\n",
      "C:\\Users\\jmanu\\AppData\\Local\\Temp\\ipykernel_3648\\3717017581.py:14: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  train_df['fechaEnvioCobro'] = pd.to_datetime(train_df['fechaEnvioCobro'], errors='coerce')\n",
      "C:\\Users\\jmanu\\AppData\\Local\\Temp\\ipykernel_3648\\3717017581.py:14: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  train_df['fechaEnvioCobro'] = pd.to_datetime(train_df['fechaEnvioCobro'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Modelo guardado en: emisora_17.parquet\n",
      "✅ Modelo guardado en: emisora_18.parquet\n",
      "✅ Modelo guardado en: emisora_19.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmanu\\AppData\\Local\\Temp\\ipykernel_3648\\3717017581.py:14: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  train_df['fechaEnvioCobro'] = pd.to_datetime(train_df['fechaEnvioCobro'], errors='coerce')\n",
      "C:\\Users\\jmanu\\AppData\\Local\\Temp\\ipykernel_3648\\3717017581.py:14: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  train_df['fechaEnvioCobro'] = pd.to_datetime(train_df['fechaEnvioCobro'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Modelo guardado en: emisora_2.parquet\n",
      "✅ Modelo guardado en: emisora_20.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmanu\\AppData\\Local\\Temp\\ipykernel_3648\\3717017581.py:14: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  train_df['fechaEnvioCobro'] = pd.to_datetime(train_df['fechaEnvioCobro'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Modelo guardado en: emisora_21.parquet\n",
      "✅ Modelo guardado en: emisora_22.parquet\n",
      "✅ Modelo guardado en: emisora_23.parquet\n",
      "✅ Modelo guardado en: emisora_24.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmanu\\AppData\\Local\\Temp\\ipykernel_3648\\3717017581.py:14: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  train_df['fechaEnvioCobro'] = pd.to_datetime(train_df['fechaEnvioCobro'], errors='coerce')\n",
      "C:\\Users\\jmanu\\AppData\\Local\\Temp\\ipykernel_3648\\3717017581.py:14: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  train_df['fechaEnvioCobro'] = pd.to_datetime(train_df['fechaEnvioCobro'], errors='coerce')\n",
      "C:\\Users\\jmanu\\AppData\\Local\\Temp\\ipykernel_3648\\3717017581.py:14: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  train_df['fechaEnvioCobro'] = pd.to_datetime(train_df['fechaEnvioCobro'], errors='coerce')\n",
      "C:\\Users\\jmanu\\AppData\\Local\\Temp\\ipykernel_3648\\3717017581.py:14: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  train_df['fechaEnvioCobro'] = pd.to_datetime(train_df['fechaEnvioCobro'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Modelo guardado en: emisora_25.parquet\n",
      "✅ Modelo guardado en: emisora_3.parquet\n",
      "✅ Modelo guardado en: emisora_4.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmanu\\AppData\\Local\\Temp\\ipykernel_3648\\3717017581.py:14: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  train_df['fechaEnvioCobro'] = pd.to_datetime(train_df['fechaEnvioCobro'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Modelo guardado en: emisora_5.parquet\n",
      "✅ Modelo guardado en: emisora_6.parquet\n",
      "✅ Modelo guardado en: emisora_9.parquet\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "files",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "151ee15a-3818-4a01-b6b8-e3b949d8bfab",
       "rows": [
        [
         "0",
         "emisora_1.parquet"
        ],
        [
         "1",
         "emisora_10.parquet"
        ],
        [
         "2",
         "emisora_11.parquet"
        ],
        [
         "3",
         "emisora_12.parquet"
        ],
        [
         "4",
         "emisora_13.parquet"
        ],
        [
         "5",
         "emisora_14.parquet"
        ],
        [
         "6",
         "emisora_15.parquet"
        ],
        [
         "7",
         "emisora_16.parquet"
        ],
        [
         "8",
         "emisora_17.parquet"
        ],
        [
         "9",
         "emisora_18.parquet"
        ],
        [
         "10",
         "emisora_19.parquet"
        ],
        [
         "11",
         "emisora_2.parquet"
        ],
        [
         "12",
         "emisora_20.parquet"
        ],
        [
         "13",
         "emisora_21.parquet"
        ],
        [
         "14",
         "emisora_22.parquet"
        ],
        [
         "15",
         "emisora_23.parquet"
        ],
        [
         "16",
         "emisora_24.parquet"
        ],
        [
         "17",
         "emisora_25.parquet"
        ],
        [
         "18",
         "emisora_3.parquet"
        ],
        [
         "19",
         "emisora_4.parquet"
        ],
        [
         "20",
         "emisora_5.parquet"
        ],
        [
         "21",
         "emisora_6.parquet"
        ],
        [
         "22",
         "emisora_9.parquet"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 23
       }
      },
      "text/plain": [
       "0      emisora_1.parquet\n",
       "1     emisora_10.parquet\n",
       "2     emisora_11.parquet\n",
       "3     emisora_12.parquet\n",
       "4     emisora_13.parquet\n",
       "5     emisora_14.parquet\n",
       "6     emisora_15.parquet\n",
       "7     emisora_16.parquet\n",
       "8     emisora_17.parquet\n",
       "9     emisora_18.parquet\n",
       "10    emisora_19.parquet\n",
       "11     emisora_2.parquet\n",
       "12    emisora_20.parquet\n",
       "13    emisora_21.parquet\n",
       "14    emisora_22.parquet\n",
       "15    emisora_23.parquet\n",
       "16    emisora_24.parquet\n",
       "17    emisora_25.parquet\n",
       "18     emisora_3.parquet\n",
       "19     emisora_4.parquet\n",
       "20     emisora_5.parquet\n",
       "21     emisora_6.parquet\n",
       "22     emisora_9.parquet\n",
       "Name: files, dtype: object"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files.files.apply(train_model_and_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f54dc2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(train_df):\n",
    "    train_df[\"dic\"] = train_df.apply(lambda x: {\n",
    "        \"bank\":str(x['IdBanco_Credito']),\n",
    "        \"payment\": float(x['montoCobrar'])\n",
    "                }, axis=1)\n",
    "    features = ['montoCobrar', 'transCount', 'IdBanco_Credito',\n",
    "                'pagoAnterior', 'ratioAnterior', 'residualAnterior', 'idEmisora', \"dic\", \"idCredito\"]\n",
    "    train_df = train_df.dropna(subset=features)\n",
    "    train_df = train_df[features]\n",
    "    train_df = pd.get_dummies(train_df, columns=['IdBanco_Credito', 'idEmisora'], drop_first=True)\n",
    "    train_df['montoCobrar'] = np.log1p(train_df['montoCobrar'])\n",
    "\n",
    "    numeric_cols = ['montoCobrar', 'transCount', 'pagoAnterior', 'ratioAnterior', 'residualAnterior']\n",
    "    scaler = StandardScaler()\n",
    "    train_df[numeric_cols] = scaler.fit_transform(train_df[numeric_cols])\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5496cb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_parquet_path=r\"D:\\Datathon 2025\\2025Test.parquet\"\n",
    "test_df = pd.read_parquet(test_parquet_path)\n",
    "test_df = preprocess(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e40280fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Datathon 2025\\.venv\\lib\\site-packages\\sklearn\\naive_bayes.py:513: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "d:\\Datathon 2025\\.venv\\lib\\site-packages\\sklearn\\naive_bayes.py:514: RuntimeWarning: divide by zero encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "d:\\Datathon 2025\\.venv\\lib\\site-packages\\sklearn\\naive_bayes.py:514: RuntimeWarning: invalid value encountered in subtract\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n"
     ]
    }
   ],
   "source": [
    "def test(x):\n",
    "    model = joblib.load(os.path.join(\"modelOut\", x))\n",
    "    test_df[list(set(model.feature_names_in_).difference(set(test_df.columns)))] = False\n",
    "    return model.predict_proba(test_df[model.feature_names_in_])\n",
    "files[\"predicts\"] = files.files.apply(test)\n",
    "files[\"emisora\"] = files.files.apply(lambda x: x[8:].split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6096b4f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "0",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "cf8c8e7a-665b-4cbc-9dff-991c8a6871b2",
       "rows": [
        [
         "0",
         null
        ],
        [
         "1",
         null
        ],
        [
         "2",
         null
        ],
        [
         "3",
         null
        ],
        [
         "4",
         null
        ],
        [
         "5",
         null
        ],
        [
         "6",
         null
        ],
        [
         "7",
         null
        ],
        [
         "8",
         null
        ],
        [
         "9",
         null
        ],
        [
         "10",
         null
        ],
        [
         "11",
         null
        ],
        [
         "12",
         null
        ],
        [
         "13",
         null
        ],
        [
         "14",
         null
        ],
        [
         "15",
         null
        ],
        [
         "16",
         null
        ],
        [
         "17",
         null
        ],
        [
         "18",
         null
        ],
        [
         "19",
         null
        ],
        [
         "20",
         null
        ],
        [
         "21",
         null
        ],
        [
         "22",
         null
        ],
        [
         "23",
         null
        ],
        [
         "24",
         null
        ],
        [
         "25",
         null
        ],
        [
         "26",
         null
        ],
        [
         "27",
         null
        ],
        [
         "28",
         null
        ],
        [
         "29",
         null
        ],
        [
         "30",
         null
        ],
        [
         "31",
         null
        ],
        [
         "32",
         null
        ],
        [
         "33",
         null
        ],
        [
         "34",
         null
        ],
        [
         "35",
         null
        ],
        [
         "36",
         null
        ],
        [
         "37",
         null
        ],
        [
         "38",
         null
        ],
        [
         "39",
         null
        ],
        [
         "40",
         null
        ],
        [
         "41",
         null
        ],
        [
         "42",
         null
        ],
        [
         "43",
         null
        ],
        [
         "44",
         null
        ],
        [
         "45",
         null
        ],
        [
         "46",
         null
        ],
        [
         "47",
         null
        ],
        [
         "48",
         null
        ],
        [
         "49",
         null
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 12796
       }
      },
      "text/plain": [
       "0        None\n",
       "1        None\n",
       "2        None\n",
       "3        None\n",
       "4        None\n",
       "         ... \n",
       "12791    None\n",
       "12792    None\n",
       "12793    None\n",
       "12794    None\n",
       "12795    None\n",
       "Length: 12796, dtype: object"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def crearJson(x):\n",
    "    json = {}\n",
    "    files.apply(lambda model: json.update({model.emisora: min(model.predicts[x.name])}), axis=1)\n",
    "    x.dic.update({\"probabilities\":json})\n",
    "test_df.apply(crearJson, axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
